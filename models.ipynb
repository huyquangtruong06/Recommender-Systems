{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae52de4-97fd-4e35-8359-13b119fedf4b",
   "metadata": {},
   "source": [
    "**Read csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d76c61-4062-4b5e-9479-579d80b99b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('rating.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81a64d-2aba-46ea-b2c0-e54db9e64336",
   "metadata": {},
   "source": [
    "**Encoding user and product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71c1fddf-b5b7-43d4-aadb-a44a22cbbe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: 0 -> 9950\n",
      "Product IDs: 0 -> 1468\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# init \n",
    "user_encoder = LabelEncoder()\n",
    "product_encoder = LabelEncoder()\n",
    "\n",
    "# fit & transform\n",
    "df['user_id_encoded'] = user_encoder.fit_transform(df['user_id'])\n",
    "df['product_id_encoded'] = product_encoder.fit_transform(df['product_id'])\n",
    "\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_products = len(product_encoder.classes_)\n",
    "\n",
    "print(f\"User IDs: 0 -> {num_users-1}\")\n",
    "print(f\"Product IDs: 0 -> {num_products-1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471afce0-bd3b-4702-b7e5-11d3afb9f729",
   "metadata": {},
   "source": [
    "**NLP Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0268598-4664-40a2-bd54-6d49719e2f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting underthesea\n",
      "  Downloading underthesea-8.3.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Click>=6.0 in e:\\anaconda\\setup\\lib\\site-packages (from underthesea) (8.1.8)\n",
      "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
      "  Downloading python_crfsuite-0.9.12-cp313-cp313-win_amd64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in e:\\anaconda\\setup\\lib\\site-packages (from underthesea) (3.9.1)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\setup\\lib\\site-packages (from underthesea) (4.67.1)\n",
      "Requirement already satisfied: requests in e:\\anaconda\\setup\\lib\\site-packages (from underthesea) (2.32.3)\n",
      "Requirement already satisfied: joblib in e:\\anaconda\\setup\\lib\\site-packages (from underthesea) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn>=1.6.1 in e:\\anaconda\\setup\\lib\\site-packages (from underthesea) (1.6.1)\n",
      "Requirement already satisfied: PyYAML in e:\\anaconda\\setup\\lib\\site-packages (from underthesea) (6.0.2)\n",
      "Collecting underthesea_core==1.0.5 (from underthesea)\n",
      "  Downloading underthesea_core-1.0.5-cp313-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting huggingface-hub (from underthesea)\n",
      "  Downloading huggingface_hub-1.3.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\setup\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.6)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\anaconda\\setup\\lib\\site-packages (from nltk>=3.8->underthesea) (2024.11.6)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\anaconda\\setup\\lib\\site-packages (from scikit-learn>=1.6.1->underthesea) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\anaconda\\setup\\lib\\site-packages (from scikit-learn>=1.6.1->underthesea) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\anaconda\\setup\\lib\\site-packages (from scikit-learn>=1.6.1->underthesea) (3.5.0)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\setup\\lib\\site-packages (from huggingface-hub->underthesea) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\anaconda\\setup\\lib\\site-packages (from huggingface-hub->underthesea) (2025.3.2)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub->underthesea)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\anaconda\\setup\\lib\\site-packages (from huggingface-hub->underthesea) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\anaconda\\setup\\lib\\site-packages (from huggingface-hub->underthesea) (24.2)\n",
      "Requirement already satisfied: shellingham in e:\\anaconda\\setup\\lib\\site-packages (from huggingface-hub->underthesea) (1.5.0)\n",
      "Collecting typer-slim (from huggingface-hub->underthesea)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in e:\\anaconda\\setup\\lib\\site-packages (from huggingface-hub->underthesea) (4.15.0)\n",
      "Requirement already satisfied: anyio in e:\\anaconda\\setup\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub->underthesea) (4.7.0)\n",
      "Requirement already satisfied: certifi in e:\\anaconda\\setup\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub->underthesea) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\anaconda\\setup\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub->underthesea) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\anaconda\\setup\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub->underthesea) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\anaconda\\setup\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub->underthesea) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\anaconda\\setup\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub->underthesea) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\setup\\lib\\site-packages (from requests->underthesea) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\setup\\lib\\site-packages (from requests->underthesea) (2.6.2)\n",
      "Downloading underthesea-8.3.0-py3-none-any.whl (8.3 MB)\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.3 MB 620.5 kB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.5/8.3 MB 620.5 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 0.8/8.3 MB 691.6 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.0/8.3 MB 718.2 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.0/8.3 MB 718.2 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 1.3/8.3 MB 722.0 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.3/8.3 MB 722.0 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 1.6/8.3 MB 734.7 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 1.8/8.3 MB 768.7 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 2.1/8.3 MB 793.8 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 2.4/8.3 MB 823.4 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 2.6/8.3 MB 855.9 kB/s eta 0:00:07\n",
      "   ------------- -------------------------- 2.9/8.3 MB 891.3 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 3.1/8.3 MB 924.0 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.4/8.3 MB 947.6 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 3.7/8.3 MB 976.3 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.2/8.3 MB 1.0 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.5/8.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.0/8.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 5.2/8.3 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.8/8.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 6.3/8.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.6/8.3 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.1/8.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.6/8.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.1/8.3 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.3/8.3 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading underthesea_core-1.0.5-cp313-none-win_amd64.whl (722 kB)\n",
      "   ---------------------------------------- 0.0/722.6 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 524.3/722.6 kB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 524.3/722.6 kB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- 722.6/722.6 kB 876.5 kB/s eta 0:00:00\n",
      "Downloading python_crfsuite-0.9.12-cp313-cp313-win_amd64.whl (303 kB)\n",
      "Downloading huggingface_hub-1.3.2-py3-none-any.whl (534 kB)\n",
      "   ---------------------------------------- 0.0/534.5 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/534.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 534.5/534.5 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.8/2.9 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.3/2.9 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.8/2.9 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.4/2.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.9/2.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.9/2.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: underthesea_core, python-crfsuite, hf-xet, typer-slim, huggingface-hub, underthesea\n",
      "\n",
      "   -------------------- ------------------- 3/6 [typer-slim]\n",
      "   -------------------- ------------------- 3/6 [typer-slim]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   -------------------------- ------------- 4/6 [huggingface-hub]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   --------------------------------- ------ 5/6 [underthesea]\n",
      "   ---------------------------------------- 6/6 [underthesea]\n",
      "\n",
      "Successfully installed hf-xet-1.2.0 huggingface-hub-1.3.2 python-crfsuite-0.9.12 typer-slim-0.21.1 underthesea-8.3.0 underthesea_core-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d589b9da-1528-47ef-929a-0db627cf3227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              comment                   tokenized_comment\n",
      "0  Tôi hài lòng về chất lượng dịch vụ  tôi hài_lòng về chất_lượng dịch_vụ\n",
      "1                  Âm thanh chân thật                  âm_thanh chân_thật\n"
     ]
    }
   ],
   "source": [
    "from underthesea import word_tokenize\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove emoji / icon\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "        \"\\U00002700-\\U000027BF\"  # dingbats\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    text = emoji_pattern.sub('', text)\n",
    "\n",
    "    # remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# clean\n",
    "df['clean_comment'] = df['comment'].apply(clean_text)\n",
    "\n",
    "# example : \"sản phẩm rất tuyệt vời\" -> [\"sản_phẩm\", \"rất\", \"tuyệt_vời\"]\n",
    "df['tokenized_comment'] = df['clean_comment'].apply(lambda x: word_tokenize(x, format=\"text\"))\n",
    "\n",
    "print(df[['comment', 'tokenized_comment']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dabeb26-5ef6-4a55-9966-d5418568a1ca",
   "metadata": {},
   "source": [
    "**Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8144ab2a-c62f-4535-9c66-200e66fa2219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước từ điển: 7398\n",
      "Shape của dữ liệu Text đầu vào: (14612, 100)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# config \n",
    "MAX_VOCAB_SIZE = 10000  # 10000 most common words\n",
    "MAX_LEN = 100 \n",
    "\n",
    "# learn vocabulary from all comment\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['tokenized_comment'])\n",
    "\n",
    "# text to string number \n",
    "sequences = tokenizer.texts_to_sequences(df['tokenized_comment'])\n",
    "\n",
    "# padding to all are equal\n",
    "X_text = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"Dimension of dictionary: {len(word_index)}\")\n",
    "print(f\"Shape of text input: {X_text.shape}\")\n",
    "\n",
    "# example: sentence \"Tuyệt vời\" convert to vector [34, 12, 0, 0, ..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26945e36-b206-494a-a9ab-2ac4303a854d",
   "metadata": {},
   "source": [
    "**[1-5] -> [0-1]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36261d40-6479-4a15-a6d2-3624be6486fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min rating: 0.0, Max rating: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y = scaler.fit_transform(df['rating'].values.reshape(-1, 1))\n",
    "\n",
    "print(f\"Min rating: {y.min()}, Max rating: {y.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a4451-20e8-4dd8-9fec-38001074b3b1",
   "metadata": {},
   "source": [
    "**Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3377b67-595a-4f6b-8f52-759039c65c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Shapes ---\n",
      "Train User: (11689,)\n",
      "Train Product: (11689,)\n",
      "Train Text: (11689, 100)\n",
      "Train Label: (11689, 1)\n",
      "[[1.  ]\n",
      " [0.5 ]\n",
      " [0.5 ]\n",
      " ...\n",
      " [1.  ]\n",
      " [0.75]\n",
      " [0.75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_user = df['user_id_encoded'].values\n",
    "X_product = df['product_id_encoded'].values\n",
    "\n",
    "X_train_u, X_test_u, X_train_p, X_test_p, X_train_t, X_test_t, y_train, y_test = train_test_split(\n",
    "    X_user, X_product, X_text, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"--- Data Shapes ---\")\n",
    "print(f\"Train User: {X_train_u.shape}\")\n",
    "print(f\"Train Product: {X_train_p.shape}\")\n",
    "print(f\"Train Text: {X_train_t.shape}\")\n",
    "print(f\"Train Label: {y_train.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9233a801-869c-4a13-a0e6-2e219cc65c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ product_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">79,608</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ product_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,752</span> │ product_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,032</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ product_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ global_average_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ product_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ user_embedding (\u001b[38;5;33mEmbedding\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │          \u001b[38;5;34m79,608\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ product_embedding (\u001b[38;5;33mEmbedding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │          \u001b[38;5;34m11,752\u001b[0m │ product_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │         \u001b[38;5;34m320,032\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ product_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ global_average_pooling1d[\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m3,136\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m33\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">416,641</span> (1.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m416,641\u001b[0m (1.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">416,641</span> (1.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m416,641\u001b[0m (1.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2 # use L2 Regularization\n",
    "\n",
    "EMBEDDING_DIM = 8       \n",
    "TEXT_EMBEDDING_DIM = 32 \n",
    "\n",
    "\n",
    "# Collaborative Filtering\n",
    "user_input = Input(shape=(1,), name='user_input')\n",
    "product_input = Input(shape=(1,), name='product_input')\n",
    "\n",
    "# add Regularization into Embedding penalty\n",
    "user_embedding = Embedding(input_dim=num_users, output_dim=EMBEDDING_DIM, embeddings_regularizer=l2(1e-4), name='user_embedding')(user_input)\n",
    "product_embedding = Embedding(input_dim=num_products, output_dim=EMBEDDING_DIM, embeddings_regularizer=l2(1e-4), name='product_embedding')(product_input)\n",
    "\n",
    "user_vec = Flatten()(user_embedding)\n",
    "product_vec = Flatten()(product_embedding)\n",
    "\n",
    "# NLP \n",
    "text_input = Input(shape=(MAX_LEN,), name='text_input')\n",
    "text_embed = Embedding(input_dim=MAX_VOCAB_SIZE + 1, output_dim=TEXT_EMBEDDING_DIM, input_length=MAX_LEN)(text_input)\n",
    "\n",
    "text_vec = GlobalAveragePooling1D()(text_embed)\n",
    "\n",
    "# Combine \"Collaborative Filtering\" vs \"NLP\"\n",
    "concat = Concatenate()([user_vec, product_vec, text_vec])\n",
    "\n",
    "# Deep Layers \n",
    "dense_1 = Dense(64, activation='relu', kernel_regularizer=l2(1e-3))(concat)\n",
    "dropout_1 = Dropout(0.5)(dense_1) # Dropout 0.5\n",
    "\n",
    "dense_2 = Dense(32, activation='relu', kernel_regularizer=l2(1e-3))(dropout_1)\n",
    "dropout_2 = Dropout(0.5)(dense_2)\n",
    "\n",
    "output = Dense(1, activation='sigmoid', name='output')(dense_2)\n",
    "\n",
    "model = Model(inputs=[user_input, product_input, text_input], outputs=output)\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24da57e0-a8a9-41ca-95bf-b104e6c43d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1507 - mae: 0.2607 - val_loss: 0.1171 - val_mae: 0.2515\n",
      "Epoch 2/20\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1020 - mae: 0.2409 - val_loss: 0.0905 - val_mae: 0.2308\n",
      "Epoch 3/20\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0799 - mae: 0.2041 - val_loss: 0.0770 - val_mae: 0.2022\n",
      "Epoch 4/20\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0664 - mae: 0.1789 - val_loss: 0.0744 - val_mae: 0.2016\n",
      "Epoch 5/20\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0560 - mae: 0.1546 - val_loss: 0.0722 - val_mae: 0.1814\n",
      "Epoch 6/20\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0468 - mae: 0.1326 - val_loss: 0.0730 - val_mae: 0.1832\n",
      "Epoch 7/20\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0417 - mae: 0.1214 - val_loss: 0.0725 - val_mae: 0.1778\n",
      "Epoch 8/20\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0382 - mae: 0.1130 - val_loss: 0.0737 - val_mae: 0.1752\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# only save model which having val_loss lowest\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# train \n",
    "history = model.fit(\n",
    "    x={'user_input': X_train_u, 'product_input': X_train_p, 'text_input': X_train_t},\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    validation_data=({'user_input': X_test_u, 'product_input': X_test_p, 'text_input': X_test_t}, y_test),\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90d79315-f5b9-40d7-8658-e04ea4b0c657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "RMSE: 0.9519 (The average error is approximately 0.95 star)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# prediction all set test\n",
    "y_pred_normalized = model.predict(\n",
    "    [X_test_u, X_test_p, X_test_t], \n",
    "    batch_size=64, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# [0-1] ->  [1-5], y_real = y_norm * (max - min) + min\n",
    "y_pred_real = y_pred_normalized * 4.0 + 1.0 \n",
    "y_true_real = y_test * 4.0 + 1.0\n",
    "\n",
    "# RMSE\n",
    "rmse = math.sqrt(mean_squared_error(y_true_real, y_pred_real))\n",
    "print(f\"RMSE: {rmse:.4f} (The average error is approximately {rmse:.2f} star)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fca4b23-c130-4cdf-8229-ba6a5db57041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result Ranking (Top-10):\n",
      "Precision@10: 0.0024\n",
      "Recall@10   : 0.0119\n",
      "NDCG@10     : 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asarray(r, dtype=float)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / dcg_max\n",
    "\n",
    "def evaluate_ranking_metrics(model, test_users_indices, df_full, k=10, num_eval_users=50):\n",
    "    \n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    unique_test_users = np.unique(test_users_indices)\n",
    "    \n",
    "    # user random\n",
    "    sampled_users = np.random.choice(unique_test_users, size=min(num_eval_users, len(unique_test_users)), replace=False)\n",
    "    \n",
    "    # Chuẩn bị dữ liệu input giả lập\n",
    "    all_product_idxs = np.arange(num_products) \n",
    "    empty_text_input = np.zeros((num_products, MAX_LEN)) \n",
    "    \n",
    "    for user_idx in tqdm(sampled_users):\n",
    "        # Ground Truth\n",
    "        user_id_real = user_encoder.inverse_transform([user_idx])[0]\n",
    "        user_data = df_full[df_full['user_id'] == user_id_real]\n",
    "        \n",
    "        # get products >= 4star from product_id_encoded\n",
    "        true_relevant_items = set(user_data[user_data['rating'] >= 4]['product_id_encoded'].values)\n",
    "        \n",
    "        if len(true_relevant_items) == 0:\n",
    "            continue \n",
    "            \n",
    "        # prediction\n",
    "        user_input_data = np.full(shape=(num_products,), fill_value=user_idx)\n",
    "        \n",
    "        predictions = model.predict(\n",
    "            [user_input_data, all_product_idxs, empty_text_input], \n",
    "            batch_size=128, verbose=0\n",
    "        ).flatten()\n",
    "        \n",
    "        # top K\n",
    "        top_k_indices = predictions.argsort()[-k:][::-1]\n",
    "        \n",
    "        # metrics\n",
    "        r = [1 if item in true_relevant_items else 0 for item in top_k_indices]\n",
    "        \n",
    "        precision = sum(r) / k\n",
    "        recall = sum(r) / len(true_relevant_items)\n",
    "        ndcg = ndcg_at_k(r, k)\n",
    "        \n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        ndcg_scores.append(ndcg)\n",
    "        \n",
    "    return np.mean(precision_scores), np.mean(recall_scores), np.mean(ndcg_scores)\n",
    "\n",
    "K = 10\n",
    "p_at_k, r_at_k, ndcg_at_k_score = evaluate_ranking_metrics(\n",
    "    model, \n",
    "    X_test_u, \n",
    "    df,  \n",
    "    k=K, \n",
    "    num_eval_users=50 \n",
    ")\n",
    "\n",
    "print(f\"\\nResult Ranking (Top-{K}):\")\n",
    "print(f\"Precision@{K}: {p_at_k:.4f}\")\n",
    "print(f\"Recall@{K}   : {r_at_k:.4f}\")\n",
    "print(f\"NDCG@{K}     : {ndcg_at_k_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63eea582-9c4a-475b-b209-da5b641e83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang gợi ý cho user ID gốc: 6652\n",
      "--- Gợi ý cho User: 6652 ---\n",
      "Sản phẩm: casio-mtp-1375l-1avdf-nam | Dự đoán: 4.67 sao\n",
      "Sản phẩm: sac-xe-hoi-3-cong-20w-xmobile-sn-156-den-xam | Dự đoán: 4.65 sao\n",
      "Sản phẩm: redmi-pad-se-8-7-wifi-4gb-64gb | Dự đoán: 4.64 sao\n",
      "Sản phẩm: loa-bluetooth-alpha-works-aw-w88 | Dự đoán: 4.63 sao\n",
      "Sản phẩm: hop-muc-brother-tn-2385-danh-cho-brother-dcpl2520d | Dự đoán: 4.62 sao\n"
     ]
    }
   ],
   "source": [
    "def recommend_products(user_id_raw, model, top_k=5):\n",
    "    # 1. Kiểm tra xem user này có trong dữ liệu huấn luyện không\n",
    "    try:\n",
    "        user_idx = user_encoder.transform([user_id_raw])[0]\n",
    "    except ValueError:\n",
    "        print(f\"User {user_id_raw} là người dùng mới, chưa có dữ liệu để gợi ý cá nhân hóa.\")\n",
    "        return []\n",
    "\n",
    "    # 2. Lấy danh sách tất cả sản phẩm\n",
    "    all_product_idxs = np.arange(num_products)\n",
    "    \n",
    "    # (Tuỳ chọn) Lọc bỏ các sản phẩm user đã mua rồi\n",
    "    # Ở đây tôi bỏ qua bước này để code đơn giản, bạn có thể thêm logic lọc nếu cần\n",
    "    \n",
    "    # 3. Chuẩn bị dữ liệu đầu vào cho mô hình\n",
    "    # - User input: Lặp lại ID của user cho bằng số lượng sản phẩm\n",
    "    user_input_data = np.full(shape=(num_products,), fill_value=user_idx)\n",
    "    \n",
    "    # - Product input: Là danh sách tất cả các sản phẩm\n",
    "    product_input_data = all_product_idxs\n",
    "    \n",
    "    # - Text input: Vì chưa mua nên chưa có comment. \n",
    "    # Ta dùng chuỗi rỗng hoặc tên sản phẩm để làm input giả lập.\n",
    "    # Ở đây ta dùng padding (toàn số 0) đại diện cho \"không có ý kiến\"\n",
    "    text_input_data = np.zeros((num_products, MAX_LEN)) \n",
    "    \n",
    "    # 4. Dự đoán (Predict)\n",
    "    # Kết quả trả về là rating dự đoán (đã chuẩn hóa 0-1)\n",
    "    predictions = model.predict(\n",
    "        [user_input_data, product_input_data, text_input_data], \n",
    "        batch_size=64, \n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # 5. Xử lý kết quả\n",
    "    # Reshape về mảng 1 chiều\n",
    "    predictions = predictions.flatten()\n",
    "    \n",
    "    # Lấy top k chỉ số có điểm dự đoán cao nhất\n",
    "    # argsort sắp xếp tăng dần, nên ta lấy những phần tử cuối cùng [-top_k:] và đảo ngược [::-1]\n",
    "    top_indices = predictions.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    # 6. Giải mã (Decode) từ số thành tên sản phẩm/ID thật\n",
    "    recommended_product_ids = product_encoder.inverse_transform(top_indices)\n",
    "    recommended_scores = predictions[top_indices] * 5.0 # Nhân 5 để về thang điểm 5 sao\n",
    "    \n",
    "    # In kết quả\n",
    "    print(f\"--- Gợi ý cho User: {user_id_raw} ---\")\n",
    "    results = []\n",
    "    for pid, score in zip(recommended_product_ids, recommended_scores):\n",
    "        print(f\"Sản phẩm: {pid} | Dự đoán: {score:.2f} sao\")\n",
    "        results.append((pid, score))\n",
    "        \n",
    "    return results\n",
    "\n",
    "sample_user = df['user_id'].iloc[0] \n",
    "print(f\"Đang gợi ý cho user ID gốc: {sample_user}\")\n",
    "\n",
    "recommendations = recommend_products(sample_user, model, top_k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
